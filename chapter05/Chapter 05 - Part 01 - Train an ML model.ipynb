{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824005bc",
   "metadata": {},
   "source": [
    "# Chapter 5 - Part 1: Model Training\n",
    "\n",
    "Welcome to chapter 5 of our Snowflake Data Scientist training series.\n",
    "\n",
    "In chapter 5 we will look at model deployment options. The code is structured into three parts:\n",
    "- Part 1: We train a model and save its binary file to disk, called the \"pickle file\".\n",
    "- Part 2: We deploy the pickle file to an Azure Function and call it via API Integration from Snowflake\n",
    "- Part 3: We deploy the pickle file directly to Snowflake using SnowPark.\n",
    "\n",
    "Happy coding!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac877c",
   "metadata": {},
   "source": [
    "### 1.) Connecting to Snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd47672",
   "metadata": {},
   "source": [
    "To connect to your Snowflake instance, make sure you have all requirements installed and your connection details ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5fd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%config SqlMagic.autocommit=False # for engines that do not support autommit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6bead40",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Make sure you have DATABASE_URL set & exported in your environment. Else run the following magic command:\n",
    "##   Snowflake driver accepts the following parameters\n",
    "##   URL = 'snowflake://<user_login_name>:<password>@<account_identifier>/<database_name>/<schema_name>?warehouse=<warehouse_name>&role=<role_name>'\n",
    "##   Example:\n",
    "##   %sql snowflake://user:password@xxxyyyzzz.west-europe.azure/DEMO/UDEMY?warehouse=PUBLIC\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8786c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT 1 as \"Connected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e95ea1",
   "metadata": {},
   "source": [
    "### 2.) Getting & transforming data from Snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affadc6a",
   "metadata": {},
   "source": [
    "First we get the data from Snowflake. Typically you'd want to do this \n",
    "as part of a CI/CD pipeline to regularly train your model. \n",
    "\n",
    "We do the following steps to get our data read:\n",
    "- Step 1: Only select the data we want the machine learning model to see, e.g. no patient ID\n",
    "- Step 2: To allow for label encoding (converting strings to numbers) we concatenate the features sex and agegroup.\n",
    "- Step 3: We then select the encoded sex& agegroup feature alongside blood pressure before and after the invention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql result_set <<\n",
    "\n",
    "---- build out all features: step 1\n",
    "with feature_table as (\n",
    "    SELECT \n",
    "        sex || ' ' || agegrp as sex_agegrp, \n",
    "        bp_before, \n",
    "        bp_after\n",
    "    FROM blood_pressure \n",
    "), \n",
    "\n",
    "---- label encoding Snowflake style: step 2\n",
    "distinct_values_table as (\n",
    "    SELECT \n",
    "        array_agg(distinct sex_agegrp) as sex_agrgrp_array \n",
    "    FROM feature_table\n",
    ")\n",
    "\n",
    "---- and return it: step 3\n",
    "SELECT\n",
    "    array_position(sex_agegrp::variant, sex_agrgrp_array) as sex_agrgrp_position,\n",
    "    bp_before,\n",
    "    bp_after\n",
    "FROM feature_table, distinct_values_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47ea9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A data object is returned. We not convert it into a Pandas dataframe for later use.\n",
    "## Convert it to Pandas\n",
    "df = result_set.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc737d2a",
   "metadata": {},
   "source": [
    "### Step 3: Prepare the data\n",
    "As part of the model training, we split our dataframe into features (X) and labels (Y). The labels are the data fields we want to predict. Further we split our dataset up into train & test sets to evaluate our performance on the dataset. Later on you'd want to do this split upstream in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "208914bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df[['sex_agrgrp_position', 'bp_before']]\n",
    "y = df['bp_after']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccad102",
   "metadata": {},
   "source": [
    "### Step 4: Train the model\n",
    "\n",
    "We select a RandomForestRegressor as our ML model for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32836145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595f29f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.7641918988124163\n"
     ]
    }
   ],
   "source": [
    "score = rfr.score(xtrain, ytrain)\n",
    "print(\"R-squared:\", score) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf112509",
   "metadata": {},
   "source": [
    "We have a model R-squared of about 0.75, meaning 75%. This means that our model explains 75% of the variation in the response variable around its mean. Not too bad for a first try ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12678f3d",
   "metadata": {},
   "source": [
    "### Step 5: Save the classifier to pickle file.\n",
    "Now that we are done training the model, we want to save it so Snowflake can use it in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9716d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "filename = 'randomforest_classifier.joblib.pkl'\n",
    "_ = joblib.dump(rfr, filename, compress=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
